{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing for sentiment analysis of Tweets\n",
    "\n",
    "This notebook has been written as part of a Kaggle challenge. The original challenge can be found here:\n",
    "https://www.kaggle.com/c/nlp-itmo-sentiment/\n",
    "\n",
    "The task given is to classify the sentiment value of a dataset of tweets in English language. The possible values that the label \"sentiment\" can assume are ['Negative','Positive'], and are stored in the training dataset as, respectively, 0 or 1.\n",
    "\n",
    "Note: all training data comes pre-labelled. Validity of this model is thus subject to the validity of the labelling process, which is dubious. It is unlikely that this model generalises well on a dataset labeled by a different person or  algorithm, whichever was used for this one.\n",
    "\n",
    "This program scores a public score of 0.77012 on Kaggle, accordingly to the f1-metric which is used. The competion is over though so the leaderboard does not show this result.\n",
    "\n",
    "Further description of the program follows in comments and markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For linear algebra and database handling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Machine learning libraries:\n",
    "#\n",
    "# 1) Vectorization and normalization of texts. Corresponds to a pipeline comprised of \n",
    "# CountVectorizer and TfidfTransformer, in this order.\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# 2) Linear classifier. Uses stochastic gradient descent to converge to a minimum of the loss function.\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# Pipeline. Imposes order in the operations.\n",
    "from sklearn.pipeline import Pipeline \n",
    "\n",
    "# GridSearchCV allows to find the optimal parameters for the ML models used\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Assorted imports for prettifying dictionaries and time handling\n",
    "from pprint import pprint\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the training dataset\n",
    "\n",
    "The dataset is provided as 'train.csv', and comprises of about 80000 tweets, labeled by sentiment value.\n",
    "\n",
    "It is not known how the label was provided.\n",
    "\n",
    "The data is first loaded, and then some exploratory analysis is performed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 79988 entries, 1 to 79999\n",
      "Data columns (total 2 columns):\n",
      "Sentiment        79988 non-null int64\n",
      "SentimentText    79988 non-null object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 1.8+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentText</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ItemID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is so sad for my APL frie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>I missed the New Moon trail...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>omg its already 7:30 :O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>.. Omgaga. Im sooo  im gunna CRy. I'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>i think mi bf is cheating on me!!!   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>or i just worry too much?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>Juuuuuuuuuuuuuuuuussssst Chillin!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>Sunny Again        Work Tomorrow  :-|  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>handed in my uniform today . i miss you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>hmmmm.... i wonder how she my number @-)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Sentiment                                      SentimentText\n",
       "ItemID                                                              \n",
       "1               0                       is so sad for my APL frie...\n",
       "2               0                     I missed the New Moon trail...\n",
       "3               1                            omg its already 7:30 :O\n",
       "4               0            .. Omgaga. Im sooo  im gunna CRy. I'...\n",
       "5               0           i think mi bf is cheating on me!!!   ...\n",
       "6               0                  or i just worry too much?        \n",
       "7               1                 Juuuuuuuuuuuuuuuuussssst Chillin!!\n",
       "8               0         Sunny Again        Work Tomorrow  :-|  ...\n",
       "9               1        handed in my uniform today . i miss you ...\n",
       "10              1           hmmmm.... i wonder how she my number @-)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv', \n",
    "                    encoding ='ISO-8859-1', # 'utf-8', which is the default encoding if no value is passed to \n",
    "                                            # the parameter encoding=, returns a UnicodeError\n",
    "                   header=0,\n",
    "                   index_col=0)\n",
    "print(train.info())\n",
    "train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no null values in the dataset, which is good. A few of the index values are missing, but this does not affect us.\n",
    "\n",
    "Since accordingly to the description of the challenge the dataset consists of tweets, it is likely that the texts contain multiple hashtags or mentions or emoticons.\n",
    " \n",
    "If their presence is significant, it might be worth to use a tokenizer specialised for tweets during preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 68253 entries, 10 to 79999\n",
      "Data columns (total 2 columns):\n",
      "Sentiment        68253 non-null int64\n",
      "SentimentText    68253 non-null object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "mask = train.SentimentText.str.contains('[@#]') # This searches for @ and # in tweets\n",
    "\n",
    "train[mask].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As displayed above, the vastest majority of the texts contain Twitter-related symbols. It is thus worth using a tokenizer with twitter-specific regex when preprocessing the texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using a Tweet tokenizer\n",
    "\n",
    "NLTK provides a tokenizer that contains Twitter-specific regex. It is important to pass the parameter reduce_len=True when instantiating the class, so that it cuts the maximum number of repeated characters to 3.\n",
    "\n",
    "Note that TfidfVectorizer normally considers the following strings as all different:\n",
    "'a','aa','aaa','aaaa','aaaaa'\n",
    "\n",
    "In the previous example, if reduce_len is set to true in preprocessing, TfidfVectorizer would receive 'a','aa', and three times 'aaa'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "tokenizer = TweetTokenizer(strip_handles=True, reduce_len=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the pipeline\n",
    "\n",
    "It is now time to build the pipeline.\n",
    "\n",
    "We will be using, in succession, TfidfVectorizer and SGDClassifier. TfidfVectorizer will use as a tokenizer the tokenizer that we have instantiated earlier. After comparing the usage of the default tokenizer of TfidfVectorizer, and the TweetTokenizer of NLTK, the latter scores better.\n",
    "\n",
    "Through GridSearch we will be searching the optimal choice of model parameters.\n",
    "\n",
    "The computation takes about 12 minutes in my computer, CPUs only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  7.8min\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed: 11.4min finished\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computation done in 712 seconds\n",
      "\n",
      "Parameters used for GridSearch: \n",
      "{'sgd__loss': ('hinge', 'log'),\n",
      " 'tfidf__ngram_range': ((1, 1), (1, 2), (1, 3), (2, 2), (2, 3)),\n",
      " 'tfidf__use_idf': (True, False)}\n",
      "\n",
      "Parameters selected as the best fit: \n",
      "{'sgd__loss': 'hinge', 'tfidf__ngram_range': (1, 2), 'tfidf__use_idf': True}\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42) # seeds the RNG for consistency in the results\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf',TfidfVectorizer(tokenizer=tokenizer.tokenize)),\n",
    "    ('sgd',SGDClassifier())\n",
    "])\n",
    "\n",
    "parameters = {'tfidf__use_idf':(True,False),               # Whether to multiply the term frequency\n",
    "                                                           # for the inverse document frequency, or not\n",
    "              \n",
    "              'tfidf__ngram_range':((1,1),(1,2),(1,3),     # Dimensionality of the ngrams to use.\n",
    "                                    (2,2),(2,3)),          # By extracting bigrams or trigrams, in addition to \n",
    "                                                           # unigram, the model should have better scoring\n",
    "              \n",
    "              'sgd__loss':('hinge','log'),                 # Possible loss functions for the classifier.\n",
    "                                                           # One is fully differentiable, the other is not.\n",
    "                                                           # Note that if 'hinge' is used, predict_proba()\n",
    "                                                           # method of the classifier cannot be called.\n",
    "             }\n",
    "\n",
    "grid_search = GridSearchCV(pipeline,\n",
    "                           parameters,\n",
    "                           n_jobs=-1,                      # Uses all CPUs available\n",
    "                           verbose=1)\n",
    "\n",
    "t = time.time()\n",
    "grid_search.fit(train.SentimentText,train.Sentiment)\n",
    "print('Computation done in {} seconds'.format(int(time.time()-t)))\n",
    "\n",
    "print('\\nParameters used for GridSearch: ')\n",
    "pprint(parameters)\n",
    "print('\\nParameters selected as the best fit: ')\n",
    "pprint(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assigning the best parameters to our model\n",
    "\n",
    "We can now assign the best scoring parameters to our model, and refit it. \n",
    "\n",
    "GridSearchCV allows to use the instantiated class to make predictions with the best-performing estimator, by calling the method GridSearchCV.predict() after fitting, which automatically uses the predict method of the best estimator. I however prefer to have more control over the model parameters, and thus choose to reinstantiate and refit the pipeline manually.\n",
    "\n",
    "Please also note that before performing grid search it is not known which loss function of the SGDClassifier will perform best. While the log-loss function, if selected as best fit, would allow to call GridSearchCV.predict_proba() after fitting, the hinge loss function would not allow it. This is an additional reason for reinstantiating the model manually, if you plan to call the predict_proba() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('tfidf',TfidfVectorizer(use_idf=True,\n",
    "                             ngram_range=(1,2),\n",
    "                             analyzer='word',\n",
    "                             tokenizer=tokenizer.tokenize\n",
    "    )),\n",
    "    ('sgd',SGDClassifier(loss='hinge',\n",
    "                         fit_intercept=True\n",
    "    ))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to fit the newly-instantiated model: 24 seconds\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "pipeline.fit(train.SentimentText,train.Sentiment)\n",
    "\n",
    "print('Time taken to fit the newly-instantiated model: {} seconds'.format(int(time.time()-t)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the test dataset\n",
    "\n",
    "The test dataset on which the program is evaluated was provided in a separate csv file, 'test.csv'.\n",
    "Be careful when loading this file, as there is an extra space in the column name that contains the texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SentimentText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80000</th>\n",
       "      <td>@ChaMberSWasHerE Oh, we've always planted rose...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80001</th>\n",
       "      <td>@chamcircuit im going 2 try your comp but as i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80002</th>\n",
       "      <td>@ChamCircuit is 13th Top Dance &amp;amp; Electroni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80003</th>\n",
       "      <td>@chamcircuit so how was Up?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80004</th>\n",
       "      <td>@chamelledesigns Quite the opposite! I'm sure ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           SentimentText\n",
       "80000  @ChaMberSWasHerE Oh, we've always planted rose...\n",
       "80001  @chamcircuit im going 2 try your comp but as i...\n",
       "80002  @ChamCircuit is 13th Top Dance &amp; Electroni...\n",
       "80003                        @chamcircuit so how was Up?\n",
       "80004  @chamelledesigns Quite the opposite! I'm sure ..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('test.csv',\n",
    "                  encoding ='ISO-8859-1',\n",
    "                  header=0,\n",
    "                  names=['SentimentText'],  # Somebody put a space in the column name :-| \n",
    "                                            # It initially reads as ' SentimentText' \n",
    "                                            # It took me a while to figure out what was wrong with it\n",
    "                   index_col=0)\n",
    "\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction time!\n",
    "\n",
    "It is now time to predict the labels of the test set with our fitted model.\n",
    "\n",
    "The results of the predictions are then saved in 'submission.csv', ready to be uploaded to Kaggle for scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 1's predicted: 12571\n",
      "Out of a total of 19999 texts\n"
     ]
    }
   ],
   "source": [
    "predictions = pipeline.predict(test.SentimentText.values)\n",
    "\n",
    "print('Number of 1\\'s predicted: {}'.format(predictions.sum()))\n",
    "print('Out of a total of {} texts'.format(len(predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80000</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80001</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80002</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80003</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80004</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentiment\n",
       "id              \n",
       "80000          0\n",
       "80001          1\n",
       "80002          1\n",
       "80003          1\n",
       "80004          1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame({'sentiment':predictions},index=test.index)\n",
    "submission.index.names = ['id']\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
